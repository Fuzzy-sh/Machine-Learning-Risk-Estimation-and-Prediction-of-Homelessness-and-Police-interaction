{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a846a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import the liberaries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm \n",
    "from sklearn.metrics import roc_curve,confusion_matrix , accuracy_score, classification_report , roc_auc_score, f1_score,precision_score, recall_score\n",
    "from plot_metric.functions import BinaryClassification\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pd.options.display.max_rows=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312441a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):    \n",
    "    '''Find data-driven cut-off for classification\n",
    "    \n",
    "    Cut-off is determied using Youden's index defined as sensitivity + specificity - 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    y_true : array, shape = [n_samples]\n",
    "        True binary labels.\n",
    "        \n",
    "    y_score : array, shape = [n_samples]\n",
    "        Target scores, can either be probability estimates of the positive class,\n",
    "        confidence values, or non-thresholded measure of decisions (as returned by\n",
    "        “decision_function” on some classifiers).\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    Ewald, B. (2006). Post hoc choice of cut points introduced bias to diagnostic research.\n",
    "    Journal of clinical epidemiology, 59(8), 798-801.\n",
    "    \n",
    "    Steyerberg, E.W., Van Calster, B., & Pencina, M.J. (2011). Performance measures for\n",
    "    prediction models and markers: evaluation of predictions and classifications.\n",
    "    Revista Espanola de Cardiologia (English Edition), 64(9), 788-794.\n",
    "    \n",
    "    Jiménez-Valverde, A., & Lobo, J.M. (2007). Threshold criteria for conversion of probability\n",
    "    of species presence to either–or presence–absence. Acta oecologica, 31(3), 361-369.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(target, predicted)\n",
    "    idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.read_hdf('df_subjects_homelessnes.h5','df_subjects_homelessnes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ead7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "day=360\n",
    "data_final=data_final[data_final['date_difference']>=timedelta(day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['homeless'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6659c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_final=data_final.join(pd.get_dummies(data_final['sex'], prefix='sex'))\n",
    "data_final['age_categorical']=data_final['age'].map(lambda x: '18-29' if ((x>=18) and (x<30)) else ('30-39' if ((x>=30) and (x<40)) else ('40-49' if ((x>=40) and (x<50)) else ('50-59' if ((x>=50) and (x<60)) else ('60+' if x>=60 else '')))) )\n",
    "data_final=data_final.join(pd.get_dummies(data_final['age_categorical'], prefix='age'))\n",
    "\n",
    "data_final[['age', 'quintmat', 'quintsoc']]=data_final[['age', 'quintmat', 'quintsoc']].apply(lambda x: x.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea230f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_hdf('ARC_Homelessness_training/data/data_final_homlessness.h5', 'data_final_homlessness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_final=data_final.join(pd.get_dummies(data_final['sex'],prefix='sex'))\n",
    "feature_list_for_training=[ \n",
    "       'sex_M',\n",
    "       'age',\n",
    "   \n",
    "       'substance', \n",
    "       'mood', \n",
    "       'anxiety', \n",
    "       'psychotic', \n",
    "       'cognitive', \n",
    "       'otherpsych',\n",
    "       'selfharm', \n",
    "    \n",
    "       'visit_emr_MH_non_elect', \n",
    "       'visit_emr_NonMH',\n",
    "       'visit_emr_visit', \n",
    "       \n",
    "       'visit_hosp_visit',\n",
    "       'visit_hospitalized_MH', \n",
    "       'visit_hospitalized_NonMH', \n",
    "    \n",
    "       'visit_family_gp', \n",
    "       'visit_im',\n",
    "       'visit_neurology', \n",
    "       'visit_other', \n",
    "       'visit_pharmacy', \n",
    "       'visit_psychiatry',\n",
    "    \n",
    "       'EX_CHF', \n",
    "       'EX_Arrhy', \n",
    "       'EX_VD', \n",
    "       'EX_PCD', \n",
    "       'EX_PVD', 'EX_HPTN_UC',\n",
    "       'EX_HPTN_C', 'EX_Para', 'Ex_OthND', 'Ex_COPD', 'Ex_Diab_UC',\n",
    "       'Ex_Diab_C', 'Ex_Hptothy', 'Ex_RF', 'Ex_LD', 'Ex_PUD_NB', 'Ex_HIV',\n",
    "       'Ex_Lymp', 'Ex_METS', 'Ex_Tumor', 'Ex_Rheum_A', 'Ex_Coag', 'Ex_Obesity',\n",
    "       'Ex_WL', 'Ex_Fluid', 'Ex_BLA', 'Ex_DA', 'Ex_Alcohol', 'Ex_Drug',\n",
    "       'Ex_Psycho', 'Ex_Dep', 'Ex_Stroke', 'Ex_Dyslipid', 'Ex_Sleep', 'Ex_IHD',\n",
    "       'EX_Fall', 'EX_Urinary', 'EX_Visual', 'EX_Hearing', 'EX_Tobacco',\n",
    "       'EX_Delirium', 'Ex_MS', 'EX_parkinsons', \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ea74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the features for training \n",
    "X=data_final[feature_list_for_training]\n",
    "# separate the labels for the training \n",
    "y=data_final['homeless']\n",
    "\n",
    "# add the constant to the x features\n",
    "X=sm.add_constant(X)\n",
    "# split the dataset into train and tes set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"### Classes percentage in the training as there are imbalanceness:\") \n",
    "print(y_train.value_counts()*100/len(y_train))\n",
    "\n",
    "# fit the model\n",
    "log_reg=sm.Logit(y_train,X_train ).fit()\n",
    "\n",
    "# after fitting the model, we need to test the model on the x_test (y_hat are the predicted probabilities)\n",
    "yhat = log_reg.predict(X_test)\n",
    "# recieve the labels from the y_hat for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal probability threshold by using the yhat as a continuous measure\n",
    "threshold = Find_Optimal_Cutoff(y_test, yhat)\n",
    "print(threshold)\n",
    "\n",
    "# Find prediction to the dataframe applying threshold :\n",
    "# choose the cutoff so that the outcome is more balanced, using either the youden index \n",
    "\n",
    "prediction = pd.Series(yhat).map(lambda x: 1 if x > threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for the test dataset\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "print (\"Confusion Matrix : \\n\", cm)\n",
    "\n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))\n",
    "\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test, prediction)))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, prediction)\n",
    "print('AUC: %.2f' % roc_auc + \"%\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(y_test, prediction, labels = [\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize = (5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b705f4",
   "metadata": {},
   "source": [
    "# Pre_processing (Balncing the classes +normalization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only balnce the classes with out normalization \n",
    "\n",
    "X=data_final[feature_list_for_training]\n",
    "\n",
    "scaler_PT = PowerTransformer() \n",
    "\n",
    "X = pd.DataFrame(scaler_PT.fit_transform(X), columns=X.columns)\n",
    "X=sm.add_constant(X)\n",
    "#split to test and training \n",
    "# x_train : features for the training the model\n",
    "# x_test :features for testing the model \n",
    "\n",
    "# y_train: the labels for the training the model\n",
    "# y_test: the labels for the testing  the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "#only oversample for the trian sets\n",
    "\n",
    "\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"### Classes percentage in the training as there are no longer any imbalanceness:\") \n",
    "print(y_train.value_counts()*100/len(y_train))\n",
    "\n",
    "\n",
    "# fit the model\n",
    "log_reg=sm.Logit(y_train,X_train ).fit()\n",
    "\n",
    "# after fitting the model, we need to test the model on the x_test (y_hat are the predicted probabilities)\n",
    "yhat = log_reg.predict(X_test)\n",
    "# recieve the labels from the y_hat for the classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal probability threshold by using the yhat as a continuous measure\n",
    "threshold = Find_Optimal_Cutoff(y_test, yhat)\n",
    "print(threshold)\n",
    "# Find prediction to the dataframe applying threshold :\n",
    "# choose the cutoff so that the outcome is more balanced, using either the youden index \n",
    "prediction = pd.Series(yhat).map(lambda x: 1 if x > threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594567ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "print (\"Confusion Matrix : \\n\", cm)\n",
    "\n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))\n",
    "\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test, prediction)))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, prediction)\n",
    "print('AUC: %.2f' % roc_auc + \"%\")\n",
    "\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(y_test, prediction, labels = [\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize = (5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a61708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
