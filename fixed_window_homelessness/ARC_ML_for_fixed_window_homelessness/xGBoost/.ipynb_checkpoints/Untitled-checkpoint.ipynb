{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566f8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1- import the liberaries\n",
    "2- return_train_test_set: read the files and create the treain and test sets\n",
    "3- confusion_AUC_Return : calculate the metrics \"roc_auc, F1,recall,precision\"\n",
    "4- train_model: train the model\n",
    "5- main : call the functions\n",
    "\n",
    "'''\n",
    "##########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, f1_score,precision_score, recall_score,roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor,BernoulliRBM\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d404597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_test_set(df_name,key):\n",
    "    # read the database from the computer \n",
    "    data_final=pd.read_hdf(df_name,key)\n",
    "\n",
    "    data_final[['age', 'quintmat', 'quintsoc']]=data_final[['age', 'quintmat', 'quintsoc']].apply(lambda x: x.astype(int))\n",
    "\n",
    "    data_final=data_final.join(pd.get_dummies(data_final['sex'],prefix='sex'))\n",
    "\n",
    "\n",
    "    feature_list_for_training=[ \n",
    "       'sex_M',\n",
    "       'age',\n",
    "    \n",
    "       'quintmat',\n",
    "       'quintsoc',\n",
    "    \n",
    "       'substance', \n",
    "       'mood', \n",
    "       'anxiety', \n",
    "       'psychotic', \n",
    "       'cognitive', \n",
    "       'otherpsych',\n",
    "       'selfharm', \n",
    "    \n",
    "       'visit_emr_MH_non_elect', \n",
    "       'visit_emr_NonMH',\n",
    "       'visit_emr_visit', \n",
    "       \n",
    "       'visit_hosp_visit',\n",
    "       'visit_hospitalized_MH', \n",
    "       'visit_hospitalized_NonMH', \n",
    "    \n",
    "       'visit_family_gp', \n",
    "       'visit_im',\n",
    "       'visit_neurology', \n",
    "       'visit_other', \n",
    "       'visit_pharmacy', \n",
    "       'visit_psychiatry',\n",
    "    \n",
    "       'EX_CHF', \n",
    "       'EX_Arrhy', \n",
    "       'EX_VD', \n",
    "       'EX_PCD', \n",
    "       'EX_PVD', 'EX_HPTN_UC',\n",
    "       'EX_HPTN_C', 'EX_Para', 'Ex_OthND', 'Ex_COPD', 'Ex_Diab_UC',\n",
    "       'Ex_Diab_C', 'Ex_Hptothy', 'Ex_RF', 'Ex_LD', 'Ex_PUD_NB', 'Ex_HIV',\n",
    "       'Ex_Lymp', 'Ex_METS', 'Ex_Tumor', 'Ex_Rheum_A', 'Ex_Coag', 'Ex_Obesity',\n",
    "       'Ex_WL', 'Ex_Fluid', 'Ex_BLA', 'Ex_DA', 'Ex_Alcohol', 'Ex_Drug',\n",
    "       'Ex_Psycho', 'Ex_Dep', 'Ex_Stroke', 'Ex_Dyslipid', 'Ex_Sleep', 'Ex_IHD',\n",
    "       'EX_Fall', 'EX_Urinary', 'EX_Visual', 'EX_Hearing', 'EX_Tobacco',\n",
    "       'EX_Delirium', 'Ex_MS', 'EX_parkinsons', \n",
    "\n",
    "]\n",
    "\n",
    "    # select the features and normalize them \n",
    "    X=data_final[feature_list_for_training]\n",
    "    scaler_PT = PowerTransformer() \n",
    "    X = pd.DataFrame(scaler_PT.fit_transform(X), columns=X.columns)\n",
    "    # target\n",
    "    y=data_final['homeless']\n",
    "    # split the data into test and training \n",
    "    x_train, x_test, y_train,  y_test=  train_test_split(X,y,test_size=0.1, random_state=42)\n",
    "    # oversampling with Random over sampler  technique \n",
    "    over_sampler = RandomOverSampler(random_state=42)\n",
    "    X_res, y_res = over_sampler.fit_resample(x_train, y_train)\n",
    "    \n",
    "    return X_res, y_res , x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb29170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# drawing the results for hyper-parameterization\n",
    "def confusion_AUC_Return(x_test,y_test,model,params):\n",
    "    # comparing original and predicted values of y\n",
    "    y_pred = model.predict(x_test)\n",
    "#     prediction = list(map(round, y_pred))\n",
    "\n",
    "    # Find prediction to the dataframe applying threshold\n",
    "    prediction = pd.Series(y_pred).map(lambda x: 1 if x > 0.5 else 0)\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "\n",
    "\n",
    "    # accuracy score of the model\n",
    "    roc_auc = roc_auc_score(y_test, prediction)\n",
    "    F1=f1_score(y_test, prediction)\n",
    "    precision=precision_score(y_test, prediction)\n",
    "    recall=recall_score(y_test, prediction)\n",
    "    return (roc_auc, F1,recall,precision)\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "def train_model( subsample,n_estimators,max_depth,learning_rate,colsample_bytree,colsample_bylevel,X_res, y_res , x_test, y_test):\n",
    "     # define the model with hyper parameters\n",
    "    xgboost_model = XGBClassifier(\n",
    "    subsample= subsample,\n",
    "    n_estimators= n_estimators,\n",
    "    max_depth= max_depth,\n",
    "    learning_rate= learning_rate,\n",
    "    colsample_bytree= colsample_bytree,\n",
    "    colsample_bylevel= colsample_bylevel)\n",
    "\n",
    "    xgboost_model.fit(X_res, y_res, )\n",
    "\n",
    "    # show the results\n",
    "    roc_auc, F1,recall,precision=confusion_AUC_Return(x_test,y_test,xgboost_model,2)\n",
    "    return roc_auc, F1,recall,precision\n",
    "    #     print('AUC: {:.2f} | F1: {:.2f} | recall: {:.2f} | precision: {:.2f}'.format(roc_auc, F1,recall,precision))\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "def main(subsample,n_estimators,max_depth,learning_rate,colsample_bytree,colsample_bylevel,file_num,model_name):   \n",
    "    df_name='../data/df_subjects_homelessnes.h5'\n",
    "    key='df_subjects_homelessnes'\n",
    "    X_res, y_res , x_test, y_test=return_train_test_set(df_name,key)    \n",
    "\n",
    "    roc_auc, F1,recall,precision=train_model (subsample,n_estimators,max_depth,learning_rate,colsample_bytree,colsample_bylevel,X_res, y_res , x_test, y_test)\n",
    "    \n",
    "    data='{},{},{},{},{},{},{:.3f},{:.3f},{:.3f},{:.3f}'.format(max_depth,learning_rate,subsample,colsample_bytree,colsample_bylevel,n_estimators,roc_auc, F1,recall,precision)\n",
    "    with open (model_name+ str(file_num)+'.csv', 'w') as fp:\n",
    "        fp.write(data)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "# max_depth=( 3 5 6 10 15 20 )\n",
    "# learning_rate=( 0.01 0.1 0.2 0.3 0.4)\n",
    "# subsample=( 0.7 0.8 0.9 )\n",
    "# colsample_bytree=( 0.4 0.5 0.6 0.7 0.8 0.9 )\n",
    "# colsample_bylevel=( 0.4 0.5 0.6 0.7 0.8 0.9 )\n",
    "# n_estimators=( 100 500 1000 )\n",
    "    \n",
    "#     max_depth=int(sys.argv[1])\n",
    "#     learning_rate=float(sys.argv[2])\n",
    "#     subsample=float(sys.argv[3])\n",
    "#     colsample_bytree=float(sys.argv[4])\n",
    "#     colsample_bylevel=float(sys.argv[5])\n",
    "#     n_estimators=int(sys.argv[6])\n",
    "#     file_num=int(sys.argv[7])\n",
    "    \n",
    "    max_depth=5\n",
    "    learning_rate=0.01\n",
    "    subsample=0.7\n",
    "    colsample_bytree=0.4\n",
    "    colsample_bylevel=0.4\n",
    "    n_estimators=100\n",
    "    file_num=1\n",
    "    model_name='../data/xGBoost/'\n",
    "    \n",
    "    main(subsample,n_estimators,max_depth,learning_rate,colsample_bytree,colsample_bylevel,file_num,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916f2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
