{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a846a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, classification_report, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from plot_metric.functions import BinaryClassification\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    '''Find data-driven cut-off for classification\n",
    "    \n",
    "    Cut-off is determined using Youden's index defined as sensitivity + specificity - 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target : array, shape = [n_samples]\n",
    "        True binary labels.\n",
    "        \n",
    "    predicted : array, shape = [n_samples]\n",
    "        Target scores, can either be probability estimates of the positive class,\n",
    "        confidence values, or non-thresholded measure of decisions (as returned by\n",
    "        “decision_function” on some classifiers).\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "    Ewald, B. (2006). Post hoc choice of cut points introduced bias to diagnostic research.\n",
    "    Journal of clinical epidemiology, 59(8), 798-801.\n",
    "    \n",
    "    Steyerberg, E.W., Van Calster, B., & Pencina, M.J. (2011). Performance measures for\n",
    "    prediction models and markers: evaluation of predictions and classifications.\n",
    "    Revista Espanola de Cardiologia (English Edition), 64(9), 788-794.\n",
    "    \n",
    "    Jiménez-Valverde, A., & Lobo, J.M. (2007). Threshold criteria for conversion of probability\n",
    "    of species presence to either–or presence–absence. Acta oecologica, 31(3), 361-369.\n",
    "    '''\n",
    "    fpr, tpr, thresholds = roc_curve(target, predicted)\n",
    "    idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[idx]\n",
    "\n",
    "def train_model(data_final):\n",
    "    feature_list_for_training = [\n",
    "        'sex_M',\n",
    "        'age',\n",
    "        'substance',\n",
    "        'mood',\n",
    "        'anxiety',\n",
    "        'psychotic',\n",
    "        'cognitive',\n",
    "        'otherpsych',\n",
    "        'selfharm',\n",
    "        'visit_emr_MH_non_elect',\n",
    "        'visit_emr_NonMH',\n",
    "        'visit_emr_visit',\n",
    "        'visit_hosp_visit',\n",
    "        'visit_hospitalized_MH',\n",
    "        'visit_hospitalized_NonMH',\n",
    "        'visit_family_gp',\n",
    "        'visit_im',\n",
    "        'visit_neurology',\n",
    "        'visit_other',\n",
    "        'visit_psychiatry',\n",
    "        'EX_CHF',\n",
    "        'EX_Arrhy',\n",
    "        'EX_VD',\n",
    "        'EX_PCD',\n",
    "        'EX_PVD',\n",
    "        'EX_HPTN_UC',\n",
    "        'EX_HPTN_C',\n",
    "        'EX_Para',\n",
    "        'Ex_OthND',\n",
    "        'Ex_COPD',\n",
    "        'Ex_Diab_UC',\n",
    "        'Ex_Diab_C',\n",
    "        'Ex_Hptothy',\n",
    "        'Ex_RF',\n",
    "        'Ex_LD',\n",
    "        'Ex_PUD_NB',\n",
    "        'Ex_HIV',\n",
    "        'Ex_Lymp',\n",
    "        'Ex_METS',\n",
    "        'Ex_Tumor',\n",
    "        'Ex_Rheum_A',\n",
    "        'Ex_Coag',\n",
    "        'Ex_Obesity',\n",
    "        'Ex_WL',\n",
    "        'Ex_Fluid',\n",
    "        'Ex_BLA',\n",
    "        'Ex_DA',\n",
    "        'Ex_Alcohol',\n",
    "        'Ex_Drug',\n",
    "        'Ex_Psycho',\n",
    "        'Ex_Dep',\n",
    "        'Ex_Stroke',\n",
    "        'Ex_Dyslipid',\n",
    "        'Ex_Sleep',\n",
    "        'Ex_IHD',\n",
    "        'EX_Fall',\n",
    "        'EX_Urinary',\n",
    "        'EX_Visual',\n",
    "        'EX_Hearing',\n",
    "        'EX_Tobacco',\n",
    "        'EX_Delirium',\n",
    "        'Ex_MS',\n",
    "        'EX_parkinsons',\n",
    "    ]\n",
    "\n",
    "    # Separate the features for training\n",
    "    X = data_final[feature_list_for_training]\n",
    "\n",
    "    # Separate the labels for the training\n",
    "    y = data_final['homeless_followup']\n",
    "\n",
    "    # Normalization\n",
    "    scaler_PT = PowerTransformer()\n",
    "    X = pd.DataFrame(scaler_PT.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Add the constant to the X features\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    # Only oversample for the train sets to balance the classes\n",
    "    over_sampler = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(\"### Classes percentage in the training as there are no longer any imbalances:\")\n",
    "    print(y_train.value_counts() * 100 / len(y_train))\n",
    "\n",
    "    # Fit the model\n",
    "    log_reg = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "    # After fitting the model, we need to test the model on the X_test (yhat are the predicted probabilities)\n",
    "    yhat = log_reg.predict(X_test)\n",
    "\n",
    "    # Find optimal probability threshold by using yhat as a continuous measure\n",
    "    threshold = Find_Optimal_Cutoff(y_test, yhat)\n",
    "\n",
    "    # Find prediction to the DataFrame applying threshold:\n",
    "    # Choose the cutoff so that the outcome is more balanced, using either the Youden index\n",
    "    prediction = pd.Series(yhat).map(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    f1 = f1_score(y_test, prediction)\n",
    "    roc_auc = roc_auc_score(y_test, prediction)\n",
    "    sensitivity = recall_score(y_test, prediction)\n",
    "    precision = precision_score(y_test, prediction)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    df_results = pd.DataFrame((round(f1, 2), round(roc_auc, 2), round(sensitivity, 2), round(precision, 2)))\n",
    "    df_results = df_results.T\n",
    "\n",
    "    return (df_results, X_train, X_test, y_train, y_test, prediction, log_reg, feature_list_for_training, y)\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "data_final = pd.read_hdf('data/df_subjects_retro_homelss.h5', 'df_subjects_retro_homelss')\n",
    "\n",
    "# Fill missing values in the 'homeless_followup' column with 0\n",
    "data_final.homeless_followup = data_final.homeless_followup.fillna(0)\n",
    "\n",
    "# Map non-zero values to 1 in the 'homeless_followup' column\n",
    "data_final['homeless_followup'] = data_final['homeless_followup'].map(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Filter the data where 'homeless_followup' is 1\n",
    "data_final[data_final['homeless_followup'] == 1]\n",
    "\n",
    "# Create dummy variables for the 'sex' column\n",
    "data_final = data_final.join(pd.get_dummies(data_final['sex'], prefix='sex'))\n",
    "\n",
    "# Categorize age into age groups\n",
    "data_final['age_categorical'] = data_final['age'].map(lambda x: '18-29' if ((x >= 18) and (x < 30)) else ('30-39' if ((x >= 30) and (x < 40)) else ('40-49' if ((x >= 40) and (x < 50)) else ('50-59' if ((x >= 50) and (x < 60)) else ('60+' if x >= 60 else '')))))\n",
    "\n",
    "# Create dummy variables for the age groups\n",
    "data_final = data_final.join(pd.get_dummies(data_final['age_categorical'], prefix='age'))\n",
    "\n",
    "print(data_final.shape)\n",
    "\n",
    "# Train the model\n",
    "df_results, X_train, X_test, y_train, y_test, prediction, log_reg, feature_list_for_training, y = train_model(data_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b705f4",
   "metadata": {},
   "source": [
    "# The results for normalized and balanced classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594567ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Accuracy score of the model\n",
    "print('Test accuracy =', accuracy_score(y_test, prediction))\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "# F1 Score\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, prediction)\n",
    "print('AUC: %.2f' % roc_auc + \"%\")\n",
    "\n",
    "# Visualisation with plot_metric\n",
    "# Create a BinaryClassification object with true labels (y_test) and predicted labels (prediction)\n",
    "bc = BinaryClassification(y_test, prediction, labels=[\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(5, 5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a61708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to a hdf file\n",
    "data_final.to_hdf('retro_ARC_Homelessness_training/data/retro_data_final_homlessness.h5', 'retro_data_final_homlessness')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
